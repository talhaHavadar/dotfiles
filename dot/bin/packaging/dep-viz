#!/usr/bin/env -S uv run --script
# /// script
# requires-python = ">=3.8"
# dependencies = [
#     "requests",
#     "graphviz",
# ]
# ///
"""Big thanks to https://github.com/hkhonming for sharing this tool with me.

This script can/may be changed to fit my needs. Please use with caution.
"""
import argparse
import requests
import gzip
import lzma
import re
import sys
from graphviz import Digraph


def fetch_repo_file(base_url, dist, path):
    """Fetches and decompresses a repository file (Packages or Sources)."""
    extensions = ["xz", "gz"]
    # Ensure URL ends with /
    if not base_url.endswith("/"):
        base_url += "/"

    for ext in extensions:
        url = f"{base_url}{path}.{ext}"
        try:
            print(f"[-] Attempting to fetch: {url}")
            response = requests.get(url, timeout=10)
            if response.status_code == 200:
                print(f"[+] Successfully fetched {url}")
                if ext == "xz":
                    return lzma.decompress(response.content).decode("utf-8")
                else:
                    return gzip.decompress(response.content).decode("utf-8")
        except Exception as e:
            print(f"[!] Connection error: {e}")
            continue

    print(f"[!] Error: Could not find or download file at {base_url}{path}")
    sys.exit(1)


def fetch_packages_file(base_url, dist, arch):
    """Fetches and decompresses the Packages file from the PPA."""
    base_path = f"dists/{dist}/main/binary-{arch}/Packages"
    return fetch_repo_file(base_url, dist, base_path)


def fetch_sources_file(base_url, dist):
    """Fetches and decompresses the Sources file from the PPA."""
    base_path = f"dists/{dist}/main/source/Sources"
    return fetch_repo_file(base_url, dist, base_path)


def parse_packages(content):
    """Parses the Packages file content into a list of dictionaries."""
    packages = []
    current_pkg = {}
    for line in content.splitlines():
        if line.strip() == "":
            if "Package" in current_pkg:
                packages.append(current_pkg)
            current_pkg = {}
            continue
        if ": " in line:
            key, value = line.split(": ", 1)
            current_pkg[key] = value.strip()

    # Capture the last package if the file doesn't end with a newline
    if "Package" in current_pkg:
        packages.append(current_pkg)
    return packages


def parse_sources(content):
    """Parses the Sources file content into a list of dictionaries.

    Handles multi-line fields (continuation lines starting with whitespace).
    """
    sources = []
    current_src = {}
    current_key = None

    for line in content.splitlines():
        if line.strip() == "":
            if "Package" in current_src:
                sources.append(current_src)
            current_src = {}
            current_key = None
            continue

        # Continuation line (starts with whitespace)
        if line.startswith(" ") or line.startswith("\t"):
            if current_key and current_key in current_src:
                current_src[current_key] += " " + line.strip()
            continue

        if ": " in line:
            key, value = line.split(": ", 1)
            current_src[key] = value.strip()
            current_key = key

    # Capture the last source if the file doesn't end with a newline
    if "Package" in current_src:
        sources.append(current_src)
    return sources


def get_source_name(pkg_info):
    """Extracts the Source package name."""
    if "Source" in pkg_info:
        return pkg_info["Source"].split(" ")[0].strip()
    return pkg_info["Package"]


def clean_dependency_name(dep_str):
    """Removes version constraints."""
    return re.sub(r"\s*\(.*?\)", "", dep_str).strip()


def get_build_depends(src_info):
    """Extracts Build-Depends from source package info (case-insensitive)."""
    # Check for Build-Depends (case-insensitive)
    for key in src_info:
        if key.lower() == "build-depends":
            return src_info[key]
    return ""


def build_binary_graph(packages):
    """Generates a graph based on Binary Package dependencies."""
    dot = Digraph(comment="PPA Binary Dependency Chart")
    dot.attr(rankdir="LR")
    dot.attr("node", shape="box", style="filled", fillcolor="lightblue")

    # Map of all binaries available in this PPA
    ppa_binaries = {p["Package"] for p in packages}

    # Track added nodes to avoid duplicates
    added_nodes = set()

    for pkg in packages:
        pkg_name = pkg["Package"]

        if pkg_name not in added_nodes:
            dot.node(pkg_name, pkg_name)
            added_nodes.add(pkg_name)

        depends_raw = pkg.get("Depends", "")
        if not depends_raw:
            continue

        for dep in depends_raw.split(","):
            dep = dep.strip()
            if not dep:
                continue
            if "|" in dep:
                dep = dep.split("|")[0].strip()

            target_bin = clean_dependency_name(dep)

            # ONLY draw if target is also in the PPA
            if target_bin in ppa_binaries:
                dot.edge(pkg_name, target_bin)

    return dot


def build_source_graph(sources):
    """Generates a graph based on Source Package Build-Depends.

    Returns:
        tuple: (Digraph, set of edges, set of source names)
    """
    dot = Digraph(comment="PPA Source Dependency Chart")
    dot.attr(rankdir="LR")
    dot.attr("node", shape="component", style="filled", fillcolor="#E0E0E0")

    # Map Binary -> Source (from the Binary field in Sources)
    bin_to_source_map = {}
    ppa_sources = set()

    for src in sources:
        src_name = src["Package"]
        ppa_sources.add(src_name)

        # The Binary field lists all binary packages built from this source
        binaries = src.get("Binary", "")
        for bin_name in binaries.split(","):
            bin_name = bin_name.strip()
            if bin_name:
                bin_to_source_map[bin_name] = src_name

    edges = set()

    for src in sources:
        src_from = src["Package"]
        build_depends_raw = get_build_depends(src)
        if not build_depends_raw:
            continue

        for dep in build_depends_raw.split(","):
            dep = dep.strip()
            if not dep:
                continue
            # Handle alternatives (pick first one)
            if "|" in dep:
                dep = dep.split("|")[0].strip()

            # Remove architecture qualifiers like :any, :native
            bin_target = clean_dependency_name(dep)
            if ":" in bin_target:
                bin_target = bin_target.split(":")[0]

            # Resolve target binary to target source
            # If bin_target is not in map, it's external (system) -> Skip
            if bin_target in bin_to_source_map:
                src_to = bin_to_source_map[bin_target]

                if src_from != src_to:
                    edges.add((src_from, src_to))

    for src in ppa_sources:
        dot.node(src, src)

    for src_from, src_to in edges:
        dot.edge(src_from, src_to)

    return dot, edges, ppa_sources


def find_strongly_connected_components(sources, edges):
    """Finds strongly connected components using Tarjan's algorithm.

    Returns:
        list of sets: Each set contains package names in one SCC
    """
    # Build adjacency list
    graph = {src: set() for src in sources}
    for src_from, src_to in edges:
        graph[src_from].add(src_to)

    index_counter = [0]
    stack = []
    lowlinks = {}
    index = {}
    on_stack = {}
    sccs = []

    def strongconnect(node):
        index[node] = index_counter[0]
        lowlinks[node] = index_counter[0]
        index_counter[0] += 1
        stack.append(node)
        on_stack[node] = True

        for successor in graph[node]:
            if successor not in index:
                strongconnect(successor)
                lowlinks[node] = min(lowlinks[node], lowlinks[successor])
            elif on_stack.get(successor, False):
                lowlinks[node] = min(lowlinks[node], index[successor])

        if lowlinks[node] == index[node]:
            scc = set()
            while True:
                successor = stack.pop()
                on_stack[successor] = False
                scc.add(successor)
                if successor == node:
                    break
            sccs.append(scc)

    for node in sources:
        if node not in index:
            strongconnect(node)

    return sccs


def compute_dependency_groups(sources, edges):
    """Computes dependency groups (topological levels) for source packages.

    Group 1: Packages with no dependencies within the PPA
    Group 2: Packages that only depend on Group 1 packages
    Group N: Packages that only depend on packages in groups < N

    Handles cyclic dependencies by detecting SCCs and marking them appropriately.

    Returns:
        tuple: (groups, cycles_info)
            - groups: list of dicts with 'packages' and 'is_cycle' keys
            - cycles_info: dict mapping cycle packages to their cycle members
    """
    # Find strongly connected components
    sccs = find_strongly_connected_components(sources, edges)

    # Identify cycles (SCCs with more than one node)
    cycles = [scc for scc in sccs if len(scc) > 1]
    cycle_packages = set()
    cycles_info = {}
    for cycle in cycles:
        for pkg in cycle:
            cycle_packages.add(pkg)
            cycles_info[pkg] = cycle

    if cycles:
        cycle_names = [', '.join(sorted(c)) for c in cycles]
        print(f"[!] Warning: Circular dependencies detected:")
        for i, cycle in enumerate(cycles, 1):
            print(f"    Cycle {i}: {', '.join(sorted(cycle))}")

    # Build adjacency list: src -> set of dependencies
    dependencies = {src: set() for src in sources}
    for src_from, src_to in edges:
        dependencies[src_from].add(src_to)

    # Create a mapping from package to its SCC representative
    pkg_to_scc = {}
    scc_to_pkgs = {}
    for i, scc in enumerate(sccs):
        rep = f"__scc_{i}__"
        scc_to_pkgs[rep] = scc
        for pkg in scc:
            pkg_to_scc[pkg] = rep

    # Build contracted graph (SCCs as nodes)
    contracted_deps = {f"__scc_{i}__": set() for i in range(len(sccs))}
    for src_from, src_to in edges:
        rep_from = pkg_to_scc[src_from]
        rep_to = pkg_to_scc[src_to]
        if rep_from != rep_to:
            contracted_deps[rep_from].add(rep_to)

    # Topological sort on contracted graph
    groups = []
    assigned = set()
    scc_reps = set(contracted_deps.keys())

    while len(assigned) < len(scc_reps):
        current_group_reps = []
        for rep in scc_reps:
            if rep in assigned:
                continue
            if contracted_deps[rep].issubset(assigned):
                current_group_reps.append(rep)

        if not current_group_reps:
            # This shouldn't happen after SCC contraction, but handle it
            remaining = [rep for rep in scc_reps if rep not in assigned]
            for rep in remaining:
                pkgs = scc_to_pkgs[rep]
                is_cycle = len(pkgs) > 1
                groups.append({'packages': sorted(pkgs), 'is_cycle': is_cycle, 'cycles': []})
            break

        # Collect all packages at this level, tracking which are cyclic
        level_packages = []
        level_cycles = []  # List of cycle sets at this level

        for rep in current_group_reps:
            pkgs = scc_to_pkgs[rep]
            if len(pkgs) > 1:
                # Cyclic SCC - sort by internal dependency count
                pkg_dep_count = {}
                for pkg in pkgs:
                    internal_deps = dependencies[pkg] & pkgs
                    pkg_dep_count[pkg] = len(internal_deps)
                sorted_pkgs = sorted(pkgs, key=lambda p: (pkg_dep_count[p], p))
                level_packages.extend(sorted_pkgs)
                level_cycles.append(pkgs)
            else:
                level_packages.extend(pkgs)

        # Sort non-cyclic packages alphabetically, keep cyclic packages in their order
        cyclic_pkg_set = set()
        for cycle in level_cycles:
            cyclic_pkg_set.update(cycle)

        non_cyclic = sorted([p for p in level_packages if p not in cyclic_pkg_set])
        cyclic_ordered = [p for p in level_packages if p in cyclic_pkg_set]

        # Combine: non-cyclic first, then cyclic
        final_packages = non_cyclic + cyclic_ordered

        groups.append({
            'packages': final_packages,
            'is_cycle': bool(level_cycles),
            'cycles': level_cycles
        })

        assigned.update(current_group_reps)

    return groups, cycles_info


def print_dependency_groups(groups, cycles_info, edges):
    """Prints dependency groups in a formatted way.

    Args:
        groups: list of dicts with 'packages', 'is_cycle', and 'cycles' keys
        cycles_info: dict mapping cycle packages to their cycle members
        edges: set of (from, to) tuples representing dependencies
    """
    # Build dependency lookup
    deps_map = {}
    for src_from, src_to in edges:
        if src_from not in deps_map:
            deps_map[src_from] = set()
        deps_map[src_from].add(src_to)

    print("\n" + "=" * 60)
    print("BUILD ORDER (Dependency Groups)")
    print("=" * 60)
    print("Packages in the same group can be built in parallel.")
    print("Groups must be built in order (Group 1 first, then Group 2, etc.)")
    print("-" * 60)

    group_num = 1
    for group_info in groups:
        packages = group_info['packages']
        cycles = group_info.get('cycles', [])

        # Build set of all cyclic packages in this group
        cyclic_pkgs = set()
        for cycle in cycles:
            cyclic_pkgs.update(cycle)

        has_cycles = bool(cyclic_pkgs)
        non_cyclic_pkgs = [p for p in packages if p not in cyclic_pkgs]

        if has_cycles:
            print(f"\nGroup {group_num} ({len(packages)} packages) [contains CYCLIC dependencies]:")

            # Show non-cyclic packages first
            if non_cyclic_pkgs:
                print(f"  Regular packages:")
                print(f"    {', '.join(non_cyclic_pkgs)}")

            # Show cyclic packages with their dependencies
            print(f"  Cyclic packages (require bootstrapping):")
            for pkg in packages:
                if pkg in cyclic_pkgs:
                    cycle_deps = deps_map.get(pkg, set()) & cyclic_pkgs
                    if cycle_deps:
                        print(f"    {pkg} -> depends on: {', '.join(sorted(cycle_deps))}")
                    else:
                        print(f"    {pkg}")
        else:
            print(f"\nGroup {group_num} ({len(packages)} package{'s' if len(packages) > 1 else ''}):")
            print(f"  {', '.join(packages)}")

        group_num += 1

    # Print summary if there were cycles
    if cycles_info:
        print("\n" + "-" * 60)
        print("CYCLE RESOLUTION NOTES:")
        print("  Packages marked as cyclic require bootstrapping:")
        print("  1. Build with reduced features or stub dependencies")
        print("  2. Rebuild with full dependencies after initial pass")

    print("\n" + "=" * 60)


def main():
    parser = argparse.ArgumentParser(description="Generate PPA Dependency Charts")

    # Required Args
    parser.add_argument(
        "--ppa",
        required=True,
        help="The base URL of the PPA (e.g., https://ppa.../ubuntu/)",
    )

    # Optional Args with Defaults
    parser.add_argument(
        "--dist", default="noble", help="Distribution codename (default: noble)"
    )
    parser.add_argument("--arch", default="arm64", help="Architecture (default: arm64)")
    parser.add_argument(
        "--output",
        default="dependency_graph",
        help="Output filename (without extension)",
    )
    parser.add_argument(
        "--mode",
        choices=["binary", "source"],
        default="binary",
        help="Graph mode: 'binary' (package-to-package) or 'source' (aggregated by source)",
    )

    args = parser.parse_args()

    # 1. Fetch and Parse
    if args.mode == "binary":
        print(f"[*] Fetching Packages metadata for {args.dist}/{args.arch}...")
        content = fetch_packages_file(args.ppa, args.dist, args.arch)
        packages = parse_packages(content)
        print(f"[*] Found {len(packages)} binary packages.")

        # 2. Build Graph
        print("[*] Generating BINARY level dependency graph...")
        dot = build_binary_graph(packages)
    else:
        print(f"[*] Fetching Sources metadata for {args.dist}...")
        content = fetch_sources_file(args.ppa, args.dist)
        sources = parse_sources(content)
        print(f"[*] Found {len(sources)} source packages.")

        # 2. Build Graph
        print("[*] Generating SOURCE level dependency graph (using Build-Depends)...")
        dot, edges, ppa_sources = build_source_graph(sources)

        # 3. Compute and print dependency groups
        groups, cycles_info = compute_dependency_groups(ppa_sources, edges)
        print_dependency_groups(groups, cycles_info, edges)

    # 4. Render
    try:
        output_path = dot.render(args.output, format="png", cleanup=True)
        print(f"[SUCCESS] Chart saved to: {output_path}")
    except Exception as e:
        print(f"[!] Error rendering graph: {e}")
        print(
            "    Ensure 'graphviz' is installed on your system (e.g., 'sudo apt install graphviz')"
        )


if __name__ == "__main__":
    main()
