#!/usr/bin/env -S uv run --script
# /// script
# requires-python = ">=3.8"
# dependencies = [
#     "requests",
#     "graphviz",
#     "python-debian",
# ]
# ///
"""Big thanks to https://github.com/hkhonming for sharing this tool with me.

This script can/may be changed to fit my needs. Please use with caution.
"""
import argparse
import json
import requests
import gzip
import lzma
import sys
from graphviz import Digraph
from debian.deb822 import Sources, Packages, PkgRelation


def fetch_repo_file(base_url, dist, path, quiet=False):
    """Fetches and decompresses a repository file (Packages or Sources)."""
    extensions = ["xz", "gz"]
    # Ensure URL ends with /
    if not base_url.endswith("/"):
        base_url += "/"

    for ext in extensions:
        url = f"{base_url}{path}.{ext}"
        try:
            if not quiet:
                print(f"[-] Attempting to fetch: {url}")
            response = requests.get(url, timeout=10)
            if response.status_code == 200:
                if not quiet:
                    print(f"[+] Successfully fetched {url}")
                if ext == "xz":
                    return lzma.decompress(response.content).decode("utf-8")
                else:
                    return gzip.decompress(response.content).decode("utf-8")
        except Exception as e:
            if not quiet:
                print(f"[!] Connection error: {e}")
            continue

    # Always print errors even in quiet mode (to stderr)
    print(f"[!] Error: Could not find or download file at {base_url}{path}", file=sys.stderr)
    sys.exit(1)


def fetch_packages_file(base_url, dist, arch, quiet=False):
    """Fetches and decompresses the Packages file from the PPA."""
    base_path = f"dists/{dist}/main/binary-{arch}/Packages"
    return fetch_repo_file(base_url, dist, base_path, quiet=quiet)


def fetch_sources_file(base_url, dist, quiet=False):
    """Fetches and decompresses the Sources file from the PPA."""
    base_path = f"dists/{dist}/main/source/Sources"
    return fetch_repo_file(base_url, dist, base_path, quiet=quiet)


def parse_packages(content):
    """Parses the Packages file content using python-debian."""
    return list(Packages.iter_paragraphs(content))


def parse_sources(content):
    """Parses the Sources file content using python-debian."""
    return list(Sources.iter_paragraphs(content))


def get_source_name(pkg_info):
    """Extracts the Source package name."""
    if "Source" in pkg_info:
        return pkg_info["Source"].split(" ")[0].strip()
    return pkg_info["Package"]


def parse_dependency_names(dep_field):
    """Parses a dependency field and returns a list of package names.

    Uses python-debian's PkgRelation to properly handle:
    - Version constraints: (>= 1.0)
    - Architecture qualifiers: [amd64 arm64]
    - Build profiles: <!nocheck>, <!pkg.foo.bar>
    - Alternatives: pkg1 | pkg2 (returns first alternative)
    - Architecture qualifiers on package: pkg:any, pkg:native

    Args:
        dep_field: Raw dependency string from Depends/Build-Depends field

    Returns:
        List of package names (strings)
    """
    if not dep_field:
        return []

    try:
        relations = PkgRelation.parse_relations(dep_field)
    except Exception:
        # Fallback to empty if parsing fails
        return []

    pkg_names = []
    for relation in relations:
        # Each relation is a list of alternatives, pick the first one
        if relation:
            first_alt = relation[0]
            pkg_name = first_alt.get("name", "")
            if pkg_name:
                # Remove architecture qualifier suffix (:any, :native, etc.)
                if ":" in pkg_name:
                    pkg_name = pkg_name.split(":")[0]
                pkg_names.append(pkg_name)

    return pkg_names


def build_binary_graph(packages):
    """Generates a graph based on Binary Package dependencies."""
    dot = Digraph(comment="PPA Binary Dependency Chart")
    dot.attr(rankdir="LR")
    dot.attr("node", shape="box", style="filled", fillcolor="lightblue")

    # Map of all binaries available in this PPA
    ppa_binaries = {p["Package"] for p in packages}

    # Track added nodes to avoid duplicates
    added_nodes = set()

    for pkg in packages:
        pkg_name = pkg["Package"]

        if pkg_name not in added_nodes:
            dot.node(pkg_name, pkg_name)
            added_nodes.add(pkg_name)

        depends_raw = pkg.get("Depends", "")
        dep_names = parse_dependency_names(depends_raw)

        for target_bin in dep_names:
            # ONLY draw if target is also in the PPA
            if target_bin in ppa_binaries:
                dot.edge(pkg_name, target_bin)

    return dot


def build_binary_transitive_deps(packages, ppa_binaries):
    """Computes transitive closure of binary dependencies within PPA.

    For each binary package in the PPA, finds all other PPA binaries it
    transitively depends on (via Depends and Pre-Depends).

    Args:
        packages: List of parsed package paragraphs
        ppa_binaries: Set of binary package names in the PPA

    Returns:
        dict: Mapping of binary name -> set of transitively dependent binaries
    """
    # Build direct dependency map (only PPA binaries)
    direct_deps = {}
    for pkg in packages:
        pkg_name = pkg["Package"]
        deps = set()

        for field in ["Depends", "Pre-Depends"]:
            dep_raw = pkg.get(field, "")
            for dep in parse_dependency_names(dep_raw):
                if dep in ppa_binaries:
                    deps.add(dep)

        direct_deps[pkg_name] = deps

    # Compute transitive closure via BFS
    closure = {}
    for pkg in ppa_binaries:
        visited = set()
        queue = list(direct_deps.get(pkg, []))

        while queue:
            dep = queue.pop(0)
            if dep in visited:
                continue
            visited.add(dep)
            queue.extend(direct_deps.get(dep, []))

        closure[pkg] = visited

    return closure


def build_source_graph(sources, packages=None):
    """Generates a graph based on Source Package Build-Depends.

    If packages (binary package info) is provided, also considers transitive
    binary dependencies. For example, if source A Build-Depends on binary X,
    and X Depends on binary Y which is built from source B, then A depends on B.

    Args:
        sources: List of parsed source paragraphs
        packages: Optional list of parsed binary package paragraphs

    Returns:
        tuple: (Digraph, set of edges, set of source names)
    """
    dot = Digraph(comment="PPA Source Dependency Chart")
    dot.attr(rankdir="LR")
    dot.attr("node", shape="component", style="filled", fillcolor="#E0E0E0")

    # Map Binary -> Source (from the Binary field in Sources)
    bin_to_source_map = {}
    ppa_sources = set()

    for src in sources:
        src_name = src["Package"]
        ppa_sources.add(src_name)

        # The Binary field lists all binary packages built from this source
        binaries = src.get("Binary", "")
        for bin_name in binaries.split(","):
            bin_name = bin_name.strip()
            if bin_name:
                bin_to_source_map[bin_name] = src_name

    # Build transitive binary dependency closure if packages provided
    ppa_binaries = set(bin_to_source_map.keys())
    bin_transitive = {}
    if packages:
        bin_transitive = build_binary_transitive_deps(packages, ppa_binaries)

    edges = set()

    for src in sources:
        src_from = src["Package"]
        build_depends_raw = src.get("Build-Depends", "")
        dep_names = parse_dependency_names(build_depends_raw)

        for bin_target in dep_names:
            # Direct dependency: Build-Depends -> binary -> source
            if bin_target in bin_to_source_map:
                src_to = bin_to_source_map[bin_target]
                if src_from != src_to:
                    edges.add((src_from, src_to))

            # Transitive dependencies through binary Depends chain
            if bin_target in bin_transitive:
                for transitive_bin in bin_transitive[bin_target]:
                    if transitive_bin in bin_to_source_map:
                        src_to = bin_to_source_map[transitive_bin]
                        if src_from != src_to:
                            edges.add((src_from, src_to))

    for src in ppa_sources:
        dot.node(src, src)

    for src_from, src_to in edges:
        dot.edge(src_from, src_to)

    return dot, edges, ppa_sources


def find_strongly_connected_components(sources, edges):
    """Finds strongly connected components using Tarjan's algorithm.

    Returns:
        list of sets: Each set contains package names in one SCC
    """
    # Build adjacency list
    graph = {src: set() for src in sources}
    for src_from, src_to in edges:
        graph[src_from].add(src_to)

    index_counter = [0]
    stack = []
    lowlinks = {}
    index = {}
    on_stack = {}
    sccs = []

    def strongconnect(node):
        index[node] = index_counter[0]
        lowlinks[node] = index_counter[0]
        index_counter[0] += 1
        stack.append(node)
        on_stack[node] = True

        for successor in graph[node]:
            if successor not in index:
                strongconnect(successor)
                lowlinks[node] = min(lowlinks[node], lowlinks[successor])
            elif on_stack.get(successor, False):
                lowlinks[node] = min(lowlinks[node], index[successor])

        if lowlinks[node] == index[node]:
            scc = set()
            while True:
                successor = stack.pop()
                on_stack[successor] = False
                scc.add(successor)
                if successor == node:
                    break
            sccs.append(scc)

    for node in sources:
        if node not in index:
            strongconnect(node)

    return sccs


def compute_dependency_groups(sources, edges, quiet=False):
    """Computes dependency groups (topological levels) for source packages.

    Group 1: Packages with no dependencies within the PPA
    Group 2: Packages that only depend on Group 1 packages
    Group N: Packages that only depend on packages in groups < N

    Handles cyclic dependencies by detecting SCCs and marking them appropriately.

    Args:
        sources: Set of source package names
        edges: Set of (from, to) tuples representing dependencies
        quiet: If True, suppress informational messages

    Returns:
        tuple: (groups, cycles_info)
            - groups: list of dicts with 'packages' and 'is_cycle' keys
            - cycles_info: dict mapping cycle packages to their cycle members
    """
    # Find strongly connected components
    sccs = find_strongly_connected_components(sources, edges)

    # Identify cycles (SCCs with more than one node)
    cycles = [scc for scc in sccs if len(scc) > 1]
    cycle_packages = set()
    cycles_info = {}
    for cycle in cycles:
        for pkg in cycle:
            cycle_packages.add(pkg)
            cycles_info[pkg] = cycle

    if cycles and not quiet:
        print(f"[!] Warning: Circular dependencies detected:")
        for i, cycle in enumerate(cycles, 1):
            print(f"    Cycle {i}: {', '.join(sorted(cycle))}")

    # Build adjacency list: src -> set of dependencies
    dependencies = {src: set() for src in sources}
    for src_from, src_to in edges:
        dependencies[src_from].add(src_to)

    # Create a mapping from package to its SCC representative
    pkg_to_scc = {}
    scc_to_pkgs = {}
    for i, scc in enumerate(sccs):
        rep = f"__scc_{i}__"
        scc_to_pkgs[rep] = scc
        for pkg in scc:
            pkg_to_scc[pkg] = rep

    # Build contracted graph (SCCs as nodes)
    contracted_deps = {f"__scc_{i}__": set() for i in range(len(sccs))}
    for src_from, src_to in edges:
        rep_from = pkg_to_scc[src_from]
        rep_to = pkg_to_scc[src_to]
        if rep_from != rep_to:
            contracted_deps[rep_from].add(rep_to)

    # Topological sort on contracted graph
    groups = []
    assigned = set()
    scc_reps = set(contracted_deps.keys())

    while len(assigned) < len(scc_reps):
        current_group_reps = []
        for rep in scc_reps:
            if rep in assigned:
                continue
            if contracted_deps[rep].issubset(assigned):
                current_group_reps.append(rep)

        if not current_group_reps:
            # This shouldn't happen after SCC contraction, but handle it
            remaining = [rep for rep in scc_reps if rep not in assigned]
            for rep in remaining:
                pkgs = scc_to_pkgs[rep]
                is_cycle = len(pkgs) > 1
                groups.append({'packages': sorted(pkgs), 'is_cycle': is_cycle, 'cycles': []})
            break

        # Collect all packages at this level, tracking which are cyclic
        level_packages = []
        level_cycles = []  # List of cycle sets at this level

        for rep in current_group_reps:
            pkgs = scc_to_pkgs[rep]
            if len(pkgs) > 1:
                # Cyclic SCC - sort by internal dependency count
                pkg_dep_count = {}
                for pkg in pkgs:
                    internal_deps = dependencies[pkg] & pkgs
                    pkg_dep_count[pkg] = len(internal_deps)
                sorted_pkgs = sorted(pkgs, key=lambda p: (pkg_dep_count[p], p))
                level_packages.extend(sorted_pkgs)
                level_cycles.append(pkgs)
            else:
                level_packages.extend(pkgs)

        # Sort non-cyclic packages alphabetically, keep cyclic packages in their order
        cyclic_pkg_set = set()
        for cycle in level_cycles:
            cyclic_pkg_set.update(cycle)

        non_cyclic = sorted([p for p in level_packages if p not in cyclic_pkg_set])
        cyclic_ordered = [p for p in level_packages if p in cyclic_pkg_set]

        # Combine: non-cyclic first, then cyclic
        final_packages = non_cyclic + cyclic_ordered

        groups.append({
            'packages': final_packages,
            'is_cycle': bool(level_cycles),
            'cycles': level_cycles
        })

        assigned.update(current_group_reps)

    return groups, cycles_info


def print_dependency_groups(groups, cycles_info, edges, json_output=False):
    """Prints dependency groups in a formatted way.

    Args:
        groups: list of dicts with 'packages', 'is_cycle', and 'cycles' keys
        cycles_info: dict mapping cycle packages to their cycle members
        edges: set of (from, to) tuples representing dependencies
        json_output: if True, output in JSON format
    """
    # Build dependency lookup
    deps_map = {}
    for src_from, src_to in edges:
        if src_from not in deps_map:
            deps_map[src_from] = set()
        deps_map[src_from].add(src_to)

    if json_output:
        output = {
            "build_order": [],
            "has_cycles": bool(cycles_info),
            "cycles": [list(cycle) for cycle in set(frozenset(c) for c in cycles_info.values())] if cycles_info else []
        }

        group_num = 1
        for group_info in groups:
            packages = group_info['packages']
            cycles = group_info.get('cycles', [])

            cyclic_pkgs = set()
            for cycle in cycles:
                cyclic_pkgs.update(cycle)

            non_cyclic_pkgs = [p for p in packages if p not in cyclic_pkgs]

            group_data = {
                "group": group_num,
                "packages": packages,
                "has_cycles": bool(cyclic_pkgs),
            }

            if cyclic_pkgs:
                group_data["regular_packages"] = non_cyclic_pkgs
                group_data["cyclic_packages"] = {}
                for pkg in packages:
                    if pkg in cyclic_pkgs:
                        cycle_deps = deps_map.get(pkg, set()) & cyclic_pkgs
                        group_data["cyclic_packages"][pkg] = list(sorted(cycle_deps))

            output["build_order"].append(group_data)
            group_num += 1

        print(json.dumps(output, indent=2))
        return

    print("\n" + "=" * 60)
    print("BUILD ORDER (Dependency Groups)")
    print("=" * 60)
    print("Packages in the same group can be built in parallel.")
    print("Groups must be built in order (Group 1 first, then Group 2, etc.)")
    print("-" * 60)

    group_num = 1
    for group_info in groups:
        packages = group_info['packages']
        cycles = group_info.get('cycles', [])

        # Build set of all cyclic packages in this group
        cyclic_pkgs = set()
        for cycle in cycles:
            cyclic_pkgs.update(cycle)

        has_cycles = bool(cyclic_pkgs)
        non_cyclic_pkgs = [p for p in packages if p not in cyclic_pkgs]

        if has_cycles:
            print(f"\nGroup {group_num} ({len(packages)} packages) [contains CYCLIC dependencies]:")

            # Show non-cyclic packages first
            if non_cyclic_pkgs:
                print(f"  Regular packages:")
                print(f"    {', '.join(non_cyclic_pkgs)}")

            # Show cyclic packages with their dependencies
            print(f"  Cyclic packages (require bootstrapping):")
            for pkg in packages:
                if pkg in cyclic_pkgs:
                    cycle_deps = deps_map.get(pkg, set()) & cyclic_pkgs
                    if cycle_deps:
                        print(f"    {pkg} -> depends on: {', '.join(sorted(cycle_deps))}")
                    else:
                        print(f"    {pkg}")
        else:
            print(f"\nGroup {group_num} ({len(packages)} package{'s' if len(packages) > 1 else ''}):")
            print(f"  {', '.join(packages)}")

        group_num += 1

    # Print summary if there were cycles
    if cycles_info:
        print("\n" + "-" * 60)
        print("CYCLE RESOLUTION NOTES:")
        print("  Packages marked as cyclic require bootstrapping:")
        print("  1. Build with reduced features or stub dependencies")
        print("  2. Rebuild with full dependencies after initial pass")

    print("\n" + "=" * 60)


def build_reverse_depends_binary(packages, target_pkg, quiet=False):
    """Finds all binary packages that depend on the target package.

    Args:
        packages: List of parsed package paragraphs
        target_pkg: Name of the package to find reverse dependencies for
        quiet: If True, suppress informational messages

    Returns:
        dict: Mapping of package name -> list of dependency types (e.g., 'Depends', 'Recommends')
    """
    # Map of all binaries available in this PPA
    ppa_binaries = {p["Package"] for p in packages}

    if target_pkg not in ppa_binaries and not quiet:
        print(f"[!] Warning: Package '{target_pkg}' not found in repository")

    reverse_deps = {}
    dep_fields = ["Depends", "Pre-Depends", "Recommends", "Suggests"]

    for pkg in packages:
        pkg_name = pkg["Package"]
        if pkg_name == target_pkg:
            continue

        for field in dep_fields:
            dep_raw = pkg.get(field, "")
            dep_names = parse_dependency_names(dep_raw)

            if target_pkg in dep_names:
                if pkg_name not in reverse_deps:
                    reverse_deps[pkg_name] = []
                reverse_deps[pkg_name].append(field)

    return reverse_deps


def build_reverse_depends_source(sources, target_pkg, quiet=False):
    """Finds all source packages that build-depend on the target package.

    Args:
        sources: List of parsed source paragraphs
        target_pkg: Name of the package (binary or source) to find reverse build-deps for
        quiet: If True, suppress informational messages

    Returns:
        dict: Mapping of source package name -> list of dependency types
    """
    # Map Binary -> Source and Source -> Binaries
    bin_to_source = {}
    source_to_binaries = {}
    ppa_sources = set()

    for src in sources:
        src_name = src["Package"]
        ppa_sources.add(src_name)
        source_to_binaries[src_name] = set()

        binaries = src.get("Binary", "")
        for bin_name in binaries.split(","):
            bin_name = bin_name.strip()
            if bin_name:
                bin_to_source[bin_name] = src_name
                source_to_binaries[src_name].add(bin_name)

    # Determine the target source and all binaries to search for
    target_source = None
    target_binaries = set()

    if target_pkg in ppa_sources:
        # Target is a source package - search for all its binaries
        target_source = target_pkg
        target_binaries = source_to_binaries.get(target_pkg, set())
        # Also include the source name itself in case it's used directly
        target_binaries.add(target_pkg)
        if not quiet:
            print(f"[*] Source package '{target_pkg}' provides: {', '.join(sorted(target_binaries - {target_pkg})) or '(none)'}")
    elif target_pkg in bin_to_source:
        # Target is a binary package - just search for that binary
        target_source = bin_to_source[target_pkg]
        target_binaries.add(target_pkg)
    else:
        # Unknown package - still try to search for it
        target_binaries.add(target_pkg)
        if not quiet:
            print(f"[!] Warning: Package '{target_pkg}' not found in repository")

    reverse_deps = {}
    dep_fields = ["Build-Depends", "Build-Depends-Indep", "Build-Depends-Arch"]

    for src in sources:
        src_name = src["Package"]
        if src_name == target_source:
            continue

        for field in dep_fields:
            dep_raw = src.get(field, "")
            dep_names = set(parse_dependency_names(dep_raw))

            # Check if any of the target binaries appear in dependencies
            matched_binaries = dep_names & target_binaries
            for matched_bin in matched_binaries:
                if src_name not in reverse_deps:
                    reverse_deps[src_name] = []
                reverse_deps[src_name].append(f"{field} ({matched_bin})")

    return reverse_deps


def build_reverse_depends_source_recursive(sources, target_pkg, quiet=False):
    """Recursively finds all source packages that depend on the target.

    Args:
        sources: List of parsed source paragraphs
        target_pkg: Name of the source package to start from
        quiet: If True, suppress informational messages

    Returns:
        dict: Mapping of source package -> dict with 'via' (dependency path) and 'deps' (direct dep info)
    """
    # Build mappings
    bin_to_source = {}
    source_to_binaries = {}
    ppa_sources = set()

    for src in sources:
        src_name = src["Package"]
        ppa_sources.add(src_name)
        source_to_binaries[src_name] = set()

        binaries = src.get("Binary", "")
        for bin_name in binaries.split(","):
            bin_name = bin_name.strip()
            if bin_name:
                bin_to_source[bin_name] = src_name
                source_to_binaries[src_name].add(bin_name)

    # Pre-compute all reverse dependencies for each source package
    dep_fields = ["Build-Depends", "Build-Depends-Indep", "Build-Depends-Arch"]
    # rdeps_map[source] = list of (dependent_source, field, matched_binary)
    rdeps_map = {src: [] for src in ppa_sources}

    for src in sources:
        src_name = src["Package"]

        for field in dep_fields:
            dep_raw = src.get(field, "")
            dep_names = set(parse_dependency_names(dep_raw))

            for dep_bin in dep_names:
                if dep_bin in bin_to_source:
                    dep_source = bin_to_source[dep_bin]
                    if dep_source != src_name:
                        rdeps_map[dep_source].append((src_name, field, dep_bin))

    # BFS to find all transitive reverse dependencies
    if target_pkg not in ppa_sources:
        if not quiet:
            print(f"[!] Warning: Source package '{target_pkg}' not found in repository")
        return {}, []

    if not quiet:
        print(f"[*] Source package '{target_pkg}' provides: {', '.join(sorted(source_to_binaries.get(target_pkg, set()))) or '(none)'}")

    visited = set()
    result = {}  # pkg -> {'level': int, 'via': [path], 'deps': [(field, binary)]}
    queue = [(target_pkg, 0, [target_pkg])]  # (package, level, path)
    traversal_order = []

    while queue:
        current, level, path = queue.pop(0)

        for dependent, field, matched_bin in rdeps_map.get(current, []):
            if dependent not in visited:
                visited.add(dependent)
                new_path = path + [dependent]
                result[dependent] = {
                    'level': level + 1,
                    'via': new_path,
                    'deps': [(field, matched_bin, current)]
                }
                traversal_order.append(dependent)
                queue.append((dependent, level + 1, new_path))
            elif dependent in result:
                # Add additional dependency info
                result[dependent]['deps'].append((field, matched_bin, current))

    return result, traversal_order


def build_reverse_depends_binary_recursive(packages, target_pkg, quiet=False):
    """Recursively finds all binary packages that depend on the target.

    Args:
        packages: List of parsed package paragraphs
        target_pkg: Name of the binary package to start from
        quiet: If True, suppress informational messages

    Returns:
        dict: Mapping of package -> dict with 'level', 'via' (path), and 'deps' info
    """
    ppa_binaries = {p["Package"] for p in packages}

    if target_pkg not in ppa_binaries and not quiet:
        print(f"[!] Warning: Package '{target_pkg}' not found in repository")

    # Pre-compute reverse dependencies
    dep_fields = ["Depends", "Pre-Depends", "Recommends", "Suggests"]
    # rdeps_map[pkg] = list of (dependent_pkg, field)
    rdeps_map = {p["Package"]: [] for p in packages}

    for pkg in packages:
        pkg_name = pkg["Package"]

        for field in dep_fields:
            dep_raw = pkg.get(field, "")
            dep_names = set(parse_dependency_names(dep_raw))

            for dep_bin in dep_names:
                if dep_bin in rdeps_map and dep_bin != pkg_name:
                    rdeps_map[dep_bin].append((pkg_name, field))

    # BFS traversal
    visited = set()
    result = {}
    queue = [(target_pkg, 0, [target_pkg])]
    traversal_order = []

    while queue:
        current, level, path = queue.pop(0)

        for dependent, field in rdeps_map.get(current, []):
            if dependent not in visited:
                visited.add(dependent)
                new_path = path + [dependent]
                result[dependent] = {
                    'level': level + 1,
                    'via': new_path,
                    'deps': [(field, current)]
                }
                traversal_order.append(dependent)
                queue.append((dependent, level + 1, new_path))
            elif dependent in result:
                result[dependent]['deps'].append((field, current))

    return result, traversal_order


def print_reverse_depends(reverse_deps, target_pkg, mode, json_output=False):
    """Prints reverse dependencies in a formatted way."""
    if json_output:
        output = {
            "target": target_pkg,
            "mode": mode,
            "count": len(reverse_deps),
            "reverse_dependencies": {
                pkg: deps for pkg, deps in sorted(reverse_deps.items())
            }
        }
        print(json.dumps(output, indent=2))
        return

    print(f"\n{'=' * 60}")
    print(f"REVERSE DEPENDENCIES FOR: {target_pkg}")
    print(f"Mode: {mode}")
    print(f"{'=' * 60}")

    if not reverse_deps:
        print(f"\nNo packages in this repository depend on '{target_pkg}'")
    else:
        print(f"\n{len(reverse_deps)} package(s) depend on '{target_pkg}':\n")

        # Sort by package name
        for pkg_name in sorted(reverse_deps.keys()):
            dep_types = reverse_deps[pkg_name]
            print(f"  {pkg_name}")
            for dep_type in dep_types:
                print(f"    - {dep_type}")

    print(f"\n{'=' * 60}")


def print_reverse_depends_recursive(result, traversal_order, target_pkg, mode, json_output=False):
    """Prints recursive reverse dependencies in a tree-like format."""
    if json_output:
        # Group by level for JSON output
        levels = {}
        for pkg, info in result.items():
            level = info['level']
            if level not in levels:
                levels[level] = []

            # Format dependencies
            deps_formatted = []
            for dep_info in info['deps']:
                if len(dep_info) == 3:  # source mode: (field, binary, source)
                    field, binary, source = dep_info
                    deps_formatted.append({
                        "field": field,
                        "binary": binary,
                        "source": source
                    })
                else:  # binary mode: (field, pkg)
                    field, dep_pkg = dep_info
                    deps_formatted.append({
                        "field": field,
                        "package": dep_pkg
                    })

            levels[level].append({
                "package": pkg,
                "path": info['via'],
                "dependencies": deps_formatted
            })

        # Sort packages within each level
        for level in levels:
            levels[level] = sorted(levels[level], key=lambda x: x['package'])

        output = {
            "target": target_pkg,
            "mode": mode,
            "recursive": True,
            "count": len(result),
            "levels": {str(k): v for k, v in sorted(levels.items())}
        }
        print(json.dumps(output, indent=2))
        return

    print(f"\n{'=' * 60}")
    print(f"RECURSIVE REVERSE DEPENDENCIES FOR: {target_pkg}")
    print(f"Mode: {mode}")
    print(f"{'=' * 60}")

    if not result:
        print(f"\nNo packages in this repository depend on '{target_pkg}'")
        print(f"\n{'=' * 60}")
        return

    # Group by level
    levels = {}
    for pkg, info in result.items():
        level = info['level']
        if level not in levels:
            levels[level] = []
        levels[level].append(pkg)

    print(f"\n{len(result)} package(s) depend on '{target_pkg}' (directly or transitively):\n")

    # Print by level
    for level in sorted(levels.keys()):
        pkgs = sorted(levels[level])
        print(f"Level {level} ({len(pkgs)} package{'s' if len(pkgs) > 1 else ''}):")

        for pkg in pkgs:
            info = result[pkg]
            # Show the dependency path
            path_str = " -> ".join(info['via'])
            print(f"  {pkg}")
            print(f"    path: {path_str}")

            # Show what it depends on
            for dep_info in info['deps']:
                if len(dep_info) == 3:  # source mode: (field, binary, source)
                    field, binary, source = dep_info
                    print(f"    - {field} ({binary}) from {source}")
                else:  # binary mode: (field, pkg)
                    field, dep_pkg = dep_info
                    print(f"    - {field} on {dep_pkg}")
        print()

    print("=" * 60)


def generate_html_graph(nodes, edges, title, output_path):
    """Generates an interactive HTML graph using Cytoscape.js.

    Args:
        nodes: Set of node names
        edges: Set of (from, to) tuples representing dependencies
        title: Title for the graph
        output_path: Path to write the HTML file
    """
    # Build node and edge data for Cytoscape
    nodes_json = [{"data": {"id": node, "label": node}} for node in sorted(nodes)]
    edges_json = [{"data": {"source": src, "target": tgt}} for src, tgt in edges]

    html_template = '''<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>''' + title + '''</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/cytoscape/3.28.1/cytoscape.min.js"></script>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, sans-serif;
            background: #1a1a2e;
            color: #eee;
            overflow: hidden;
        }
        #cy {
            width: 100vw;
            height: 100vh;
            position: absolute;
            top: 0;
            left: 0;
        }
        #controls {
            position: fixed;
            top: 20px;
            left: 20px;
            z-index: 1000;
            background: rgba(30, 30, 50, 0.95);
            padding: 15px 20px;
            border-radius: 12px;
            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.5);
            max-width: 320px;
        }
        #controls h3 {
            margin-bottom: 10px;
            font-size: 14px;
            color: #888;
            text-transform: uppercase;
            letter-spacing: 1px;
        }
        #search-container {
            margin-bottom: 12px;
        }
        #search-input {
            width: 100%;
            padding: 8px 12px;
            border: 1px solid rgba(255,255,255,0.2);
            border-radius: 6px;
            background: rgba(0,0,0,0.3);
            color: #fff;
            font-size: 13px;
            outline: none;
            transition: border-color 0.2s;
        }
        #search-input:focus {
            border-color: #4ecdc4;
        }
        #search-input::placeholder {
            color: #666;
        }
        #search-input.matched {
            border-color: #4ecdc4;
            background: rgba(78, 205, 196, 0.1);
        }
        #search-input.no-match {
            border-color: #ff6b6b;
            background: rgba(255, 107, 107, 0.1);
        }
        #mode-indicator {
            font-size: 13px;
            padding: 8px 12px;
            background: rgba(100, 100, 140, 0.3);
            border-radius: 6px;
            margin-bottom: 12px;
        }
        #mode-indicator .mode-label {
            color: #aaa;
        }
        #mode-indicator .mode-value {
            font-weight: 600;
            color: #fff;
        }
        .legend {
            display: flex;
            flex-direction: column;
            gap: 8px;
            font-size: 12px;
            margin-top: 12px;
            padding: 12px 0;
            border-top: 1px solid rgba(255,255,255,0.1);
        }
        .legend-item {
            display: flex;
            align-items: center;
            gap: 8px;
            padding: 4px 0;
        }
        .legend-color {
            width: 14px;
            height: 14px;
            border-radius: 3px;
        }
        .legend-color.depends {
            background: #4ecdc4;
        }
        .legend-color.rdepends {
            background: #ff6b6b;
        }
        .legend-color.both {
            background: #ffe66d;
        }
        .legend-color.dimmed {
            background: rgba(100, 100, 100, 0.3);
        }
        #help {
            margin-top: 15px;
            padding: 12px 0;
            border-top: 1px solid rgba(255,255,255,0.1);
            font-size: 11px;
            color: #666;
            display: flex;
            flex-direction: column;
            gap: 8px;
        }
        #help p {
            padding: 4px 0;
        }
        #help kbd {
            background: rgba(255,255,255,0.1);
            padding: 2px 6px;
            border-radius: 3px;
            font-family: monospace;
        }
        #node-info {
            position: fixed;
            bottom: 20px;
            left: 20px;
            z-index: 1000;
            background: rgba(30, 30, 50, 0.95);
            padding: 15px 20px;
            border-radius: 12px;
            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.5);
            max-width: 400px;
            display: none;
        }
        #node-info h4 {
            color: #4ecdc4;
            margin-bottom: 8px;
            font-size: 16px;
        }
        #node-info .stats {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 8px;
            font-size: 12px;
        }
        #node-info .stat {
            padding: 6px 10px;
            background: rgba(100, 100, 140, 0.2);
            border-radius: 4px;
        }
        #node-info .stat-label {
            color: #888;
        }
        #node-info .stat-value {
            font-weight: 600;
        }
        #node-info .stat-value.depends {
            color: #4ecdc4;
        }
        #node-info .stat-value.rdepends {
            color: #ff6b6b;
        }
    </style>
</head>
<body>
    <div id="cy"></div>
    <div id="controls">
        <h3>Dependency Graph</h3>
        <div id="search-container">
            <input type="text" id="search-input" placeholder="Search package..." autocomplete="off" />
        </div>
        <div id="mode-indicator">
            <span class="mode-label">Highlight mode:</span>
            <span class="mode-value" id="mode-text">Both</span>
        </div>
        <div class="legend">
            <div class="legend-item">
                <div class="legend-color depends"></div>
                <span>Dependencies (packages I depend on)</span>
            </div>
            <div class="legend-item">
                <div class="legend-color rdepends"></div>
                <span>Reverse dependencies (depend on me)</span>
            </div>
            <div class="legend-item">
                <div class="legend-color both"></div>
                <span>Current node</span>
            </div>
            <div class="legend-item">
                <div class="legend-color dimmed"></div>
                <span>Unrelated packages</span>
            </div>
        </div>
        <div id="help">
            <p><kbd>Space</kbd> Toggle highlight mode</p>
            <p><kbd>Esc</kbd> Clear search</p>
            <p><kbd>Scroll</kbd> Zoom in/out</p>
            <p><kbd>Drag</kbd> Pan the graph</p>
        </div>
    </div>
    <div id="node-info">
        <h4 id="node-name"></h4>
        <div class="stats">
            <div class="stat">
                <span class="stat-label">Dependencies: </span>
                <span class="stat-value depends" id="dep-count">0</span>
            </div>
            <div class="stat">
                <span class="stat-label">Reverse deps: </span>
                <span class="stat-value rdepends" id="rdep-count">0</span>
            </div>
        </div>
    </div>
    <script>
        const graphData = {
            nodes: ''' + json.dumps(nodes_json) + ''',
            edges: ''' + json.dumps(edges_json) + '''
        };

        // Pre-compute dependency relationships for fast lookup
        const dependencies = {};  // node -> set of nodes it depends on (transitively)
        const reverseDeps = {};   // node -> set of nodes that depend on it (transitively)

        // Initialize
        graphData.nodes.forEach(n => {
            dependencies[n.data.id] = new Set();
            reverseDeps[n.data.id] = new Set();
        });

        // Build direct dependency map
        const directDeps = {};
        const directRdeps = {};
        graphData.nodes.forEach(n => {
            directDeps[n.data.id] = new Set();
            directRdeps[n.data.id] = new Set();
        });
        graphData.edges.forEach(e => {
            directDeps[e.data.source].add(e.data.target);
            directRdeps[e.data.target].add(e.data.source);
        });

        // Compute transitive closure for dependencies
        function computeTransitive(directMap, resultMap) {
            Object.keys(directMap).forEach(node => {
                const visited = new Set();
                const queue = [...directMap[node]];
                while (queue.length > 0) {
                    const current = queue.shift();
                    if (visited.has(current)) continue;
                    visited.add(current);
                    resultMap[node].add(current);
                    directMap[current].forEach(next => {
                        if (!visited.has(next)) queue.push(next);
                    });
                }
            });
        }

        computeTransitive(directDeps, dependencies);
        computeTransitive(directRdeps, reverseDeps);

        // Highlight modes: 0 = both, 1 = dependencies only, 2 = reverse deps only
        let highlightMode = 0;
        const modeNames = ['Both', 'Dependencies only', 'Reverse deps only'];

        const cy = cytoscape({
            container: document.getElementById('cy'),
            elements: [...graphData.nodes, ...graphData.edges],
            style: [
                {
                    selector: 'node',
                    style: {
                        'background-color': '#6c7a89',
                        'label': 'data(label)',
                        'color': '#fff',
                        'text-valign': 'center',
                        'text-halign': 'center',
                        'font-size': '10px',
                        'font-weight': '500',
                        'width': 'label',
                        'height': '30px',
                        'padding': '10px',
                        'shape': 'round-rectangle',
                        'text-wrap': 'none',
                        'border-width': 2,
                        'border-color': '#4a5568',
                        'transition-property': 'background-color, border-color, opacity',
                        'transition-duration': '0.2s'
                    }
                },
                {
                    selector: 'edge',
                    style: {
                        'width': 2,
                        'line-color': '#4a5568',
                        'target-arrow-color': '#4a5568',
                        'target-arrow-shape': 'triangle',
                        'curve-style': 'bezier',
                        'arrow-scale': 1.2,
                        'transition-property': 'line-color, target-arrow-color, opacity',
                        'transition-duration': '0.2s'
                    }
                },
                {
                    selector: 'node.dimmed',
                    style: {
                        'opacity': 0.15
                    }
                },
                {
                    selector: 'edge.dimmed',
                    style: {
                        'opacity': 0.08
                    }
                },
                {
                    selector: 'node.highlighted-current',
                    style: {
                        'background-color': '#ffe66d',
                        'border-color': '#f5c842',
                        'border-width': 3,
                        'color': '#1a1a2e'
                    }
                },
                {
                    selector: 'node.highlighted-depends',
                    style: {
                        'background-color': '#4ecdc4',
                        'border-color': '#26a69a',
                        'border-width': 3,
                        'color': '#1a1a2e'
                    }
                },
                {
                    selector: 'node.highlighted-rdepends',
                    style: {
                        'background-color': '#ff6b6b',
                        'border-color': '#e53935',
                        'border-width': 3,
                        'color': '#fff'
                    }
                },
                {
                    selector: 'edge.highlighted-depends',
                    style: {
                        'line-color': '#4ecdc4',
                        'target-arrow-color': '#4ecdc4',
                        'width': 3
                    }
                },
                {
                    selector: 'edge.highlighted-rdepends',
                    style: {
                        'line-color': '#ff6b6b',
                        'target-arrow-color': '#ff6b6b',
                        'width': 3
                    }
                }
            ],
            layout: {
                name: 'cose',
                idealEdgeLength: 120,
                nodeOverlap: 20,
                refresh: 20,
                fit: true,
                padding: 50,
                randomize: false,
                componentSpacing: 100,
                nodeRepulsion: 8000,
                edgeElasticity: 100,
                nestingFactor: 5,
                gravity: 0.25,
                numIter: 1000,
                initialTemp: 200,
                coolingFactor: 0.95,
                minTemp: 1.0
            },
            minZoom: 0.2,
            maxZoom: 3,
            wheelSensitivity: 0.3
        });

        let hoveredNode = null;

        // Search state
        const searchInput = document.getElementById('search-input');
        const allNodeNames = new Set(graphData.nodes.map(n => n.data.id));
        let searchedNode = null;

        function clearHighlights() {
            cy.elements().removeClass('dimmed highlighted-current highlighted-depends highlighted-rdepends');
        }

        function applyHighlights(nodeId) {
            if (!nodeId) return;

            const deps = dependencies[nodeId] || new Set();
            const rdeps = reverseDeps[nodeId] || new Set();

            const showDeps = highlightMode === 0 || highlightMode === 1;
            const showRdeps = highlightMode === 0 || highlightMode === 2;

            // Determine which nodes to highlight
            const highlightedNodes = new Set([nodeId]);
            if (showDeps) deps.forEach(d => highlightedNodes.add(d));
            if (showRdeps) rdeps.forEach(r => highlightedNodes.add(r));

            // Dim all elements first
            cy.elements().addClass('dimmed');

            // Remove dimmed from highlighted nodes and apply highlight classes
            cy.nodes().forEach(node => {
                const id = node.id();
                if (highlightedNodes.has(id)) {
                    node.removeClass('dimmed');
                    if (id === nodeId) {
                        node.addClass('highlighted-current');
                    } else if (showDeps && deps.has(id)) {
                        node.addClass('highlighted-depends');
                    } else if (showRdeps && rdeps.has(id)) {
                        node.addClass('highlighted-rdepends');
                    }
                }
            });

            // Highlight edges
            cy.edges().forEach(edge => {
                const src = edge.source().id();
                const tgt = edge.target().id();

                // Edge from current node to a dependency
                if (showDeps && src === nodeId && deps.has(tgt)) {
                    edge.removeClass('dimmed');
                    edge.addClass('highlighted-depends');
                }
                // Edge within dependencies (transitive)
                else if (showDeps && deps.has(src) && deps.has(tgt)) {
                    edge.removeClass('dimmed');
                    edge.addClass('highlighted-depends');
                }
                // Edge from rdep to current node
                else if (showRdeps && tgt === nodeId && rdeps.has(src)) {
                    edge.removeClass('dimmed');
                    edge.addClass('highlighted-rdepends');
                }
                // Edge within reverse dependencies (transitive)
                else if (showRdeps && rdeps.has(src) && rdeps.has(tgt)) {
                    edge.removeClass('dimmed');
                    edge.addClass('highlighted-rdepends');
                }
            });
        }

        function updateModeIndicator() {
            document.getElementById('mode-text').textContent = modeNames[highlightMode];
        }

        function updateNodeInfo(nodeId) {
            const nodeInfo = document.getElementById('node-info');
            if (!nodeId) {
                nodeInfo.style.display = 'none';
                return;
            }
            const deps = dependencies[nodeId] || new Set();
            const rdeps = reverseDeps[nodeId] || new Set();

            document.getElementById('node-name').textContent = nodeId;
            document.getElementById('dep-count').textContent = deps.size;
            document.getElementById('rdep-count').textContent = rdeps.size;
            nodeInfo.style.display = 'block';
        }

        cy.on('mouseover', 'node', function(e) {
            hoveredNode = e.target.id();
            clearHighlights();
            applyHighlights(hoveredNode);
            updateNodeInfo(hoveredNode);
        });

        cy.on('mouseout', 'node', function(e) {
            hoveredNode = null;
            // If there's a searched node, keep that highlighted
            if (searchedNode) {
                clearHighlights();
                applyHighlights(searchedNode);
                updateNodeInfo(searchedNode);
            } else {
                clearHighlights();
                updateNodeInfo(null);
            }
        });

        document.addEventListener('keydown', function(e) {
            // Don't intercept space when typing in search
            if (e.code === 'Space' && document.activeElement !== searchInput) {
                e.preventDefault();
                highlightMode = (highlightMode + 1) % 3;
                updateModeIndicator();
                if (hoveredNode || searchedNode) {
                    clearHighlights();
                    applyHighlights(hoveredNode || searchedNode);
                }
            }
        });

        // Search functionality
        searchInput.addEventListener('input', function(e) {
            const query = e.target.value.trim().toLowerCase();
            searchInput.classList.remove('matched', 'no-match');

            if (!query) {
                searchedNode = null;
                if (!hoveredNode) {
                    clearHighlights();
                    updateNodeInfo(null);
                }
                return;
            }

            // Find exact match (case-insensitive)
            let matchedNode = null;
            for (const name of allNodeNames) {
                if (name.toLowerCase() === query) {
                    matchedNode = name;
                    break;
                }
            }

            if (matchedNode) {
                searchInput.classList.add('matched');
                searchedNode = matchedNode;
                clearHighlights();
                applyHighlights(matchedNode);
                updateNodeInfo(matchedNode);

                // Center view on the matched node
                const node = cy.getElementById(matchedNode);
                cy.animate({
                    center: { eles: node },
                    duration: 300
                });
            } else {
                searchInput.classList.add('no-match');
                searchedNode = null;
                if (!hoveredNode) {
                    clearHighlights();
                    updateNodeInfo(null);
                }
            }
        });

        // Clear search when hovering a node
        cy.on('mouseover', 'node', function() {
            searchInput.value = '';
            searchInput.classList.remove('matched', 'no-match');
            searchedNode = null;
        });

        // Escape key clears search
        searchInput.addEventListener('keydown', function(e) {
            if (e.code === 'Escape') {
                searchInput.value = '';
                searchInput.classList.remove('matched', 'no-match');
                searchedNode = null;
                searchInput.blur();
                clearHighlights();
                updateNodeInfo(null);
            }
        });

        updateModeIndicator();
    </script>
</body>
</html>'''

    with open(output_path, 'w') as f:
        f.write(html_template)

    return output_path


def build_binary_edges(packages):
    """Builds edge set for binary package dependencies.

    Args:
        packages: List of parsed package paragraphs

    Returns:
        tuple: (set of package names, set of (from, to) edges)
    """
    ppa_binaries = {p["Package"] for p in packages}
    edges = set()

    for pkg in packages:
        pkg_name = pkg["Package"]
        depends_raw = pkg.get("Depends", "")
        dep_names = parse_dependency_names(depends_raw)

        for target_bin in dep_names:
            if target_bin in ppa_binaries and target_bin != pkg_name:
                edges.add((pkg_name, target_bin))

    return ppa_binaries, edges


def main():
    parser = argparse.ArgumentParser(description="Generate PPA Dependency Charts")

    # Required Args
    parser.add_argument(
        "--ppa",
        required=True,
        help="The base URL of the PPA (e.g., https://ppa.../ubuntu/)",
    )

    # Optional Args with Defaults
    parser.add_argument(
        "--dist", default="noble", help="Distribution codename (default: noble)"
    )
    parser.add_argument(
        "--arch", default="amd64",
        help="Architecture for binary mode (default: amd64). "
             "Only applies to --mode=binary. Common values: amd64, arm64, i386"
    )
    parser.add_argument(
        "--output",
        default="dependency_graph",
        help="Output filename (without extension)",
    )
    parser.add_argument(
        "--mode",
        choices=["binary", "source"],
        default="binary",
        help="Graph mode: 'binary' (package-to-package) or 'source' (aggregated by source)",
    )
    parser.add_argument(
        "--rdepends",
        metavar="PACKAGE",
        help="Show reverse dependencies for the specified package (like reverse-depends)",
    )
    parser.add_argument(
        "-X", "--recursive",
        action="store_true",
        help="Recursively follow reverse dependencies (only valid with --rdepends)",
    )
    parser.add_argument(
        "--json",
        action="store_true",
        help="Output results in JSON format",
    )
    parser.add_argument(
        "--format",
        choices=["png", "html"],
        default="png",
        help="Output format: 'png' (static graph) or 'html' (interactive visualization)",
    )

    args = parser.parse_args()

    # Validate -X is only used with --rdepends
    if args.recursive and not args.rdepends:
        parser.error("-X/--recursive requires --rdepends")

    # Note about --arch in source mode (it's used for binary transitive deps)
    # No longer printing a warning since --arch IS used to fetch Packages for
    # resolving transitive binary dependencies in source mode

    # Helper to print status messages (suppressed in JSON mode)
    def log(msg):
        if not args.json:
            print(msg)

    # 1. Fetch and Parse
    if args.mode == "binary":
        log(f"[*] Fetching Packages metadata for {args.dist}/{args.arch}...")
        content = fetch_packages_file(args.ppa, args.dist, args.arch, quiet=args.json)
        packages = parse_packages(content)
        log(f"[*] Found {len(packages)} binary packages.")

        # Handle reverse depends query
        if args.rdepends:
            mode_str = f"binary ({args.arch})"
            if args.recursive:
                result, order = build_reverse_depends_binary_recursive(packages, args.rdepends, quiet=args.json)
                print_reverse_depends_recursive(result, order, args.rdepends, mode_str, args.json)
            else:
                reverse_deps = build_reverse_depends_binary(packages, args.rdepends, quiet=args.json)
                print_reverse_depends(reverse_deps, args.rdepends, mode_str, args.json)
            return

        # 2. Build Graph
        log("[*] Generating BINARY level dependency graph...")
        ppa_binaries, edges = build_binary_edges(packages)
        dot = build_binary_graph(packages)
        graph_nodes = ppa_binaries
        graph_edges = edges
    else:
        log(f"[*] Fetching Sources metadata for {args.dist}...")
        content = fetch_sources_file(args.ppa, args.dist, quiet=args.json)
        sources = parse_sources(content)
        log(f"[*] Found {len(sources)} source packages.")

        # Also fetch Packages to resolve transitive binary dependencies
        log(f"[*] Fetching Packages metadata for {args.dist}/{args.arch} (for transitive deps)...")
        pkg_content = fetch_packages_file(args.ppa, args.dist, args.arch, quiet=args.json)
        packages = parse_packages(pkg_content)
        log(f"[*] Found {len(packages)} binary packages.")

        # Handle reverse depends query
        if args.rdepends:
            if args.recursive:
                result, order = build_reverse_depends_source_recursive(sources, args.rdepends, quiet=args.json)
                print_reverse_depends_recursive(result, order, args.rdepends, "source (Build-Depends)", args.json)
            else:
                reverse_deps = build_reverse_depends_source(sources, args.rdepends, quiet=args.json)
                print_reverse_depends(reverse_deps, args.rdepends, "source (Build-Depends)", args.json)
            return

        # 2. Build Graph (with transitive binary deps)
        log("[*] Generating SOURCE level dependency graph (using Build-Depends + transitive binary deps)...")
        dot, edges, ppa_sources = build_source_graph(sources, packages)
        graph_nodes = ppa_sources
        graph_edges = edges

        # 3. Compute and print dependency groups
        groups, cycles_info = compute_dependency_groups(ppa_sources, edges, quiet=args.json)
        print_dependency_groups(groups, cycles_info, edges, args.json)

    # 4. Render
    if args.format == "html":
        title = f"PPA Dependency Graph ({args.mode} mode) - {args.dist}"
        output_path = f"{args.output}.html"
        generate_html_graph(graph_nodes, graph_edges, title, output_path)
        print(f"[SUCCESS] Interactive chart saved to: {output_path}")
    else:
        try:
            output_path = dot.render(args.output, format="png", cleanup=True)
            print(f"[SUCCESS] Chart saved to: {output_path}")
        except Exception as e:
            print(f"[!] Error rendering graph: {e}")
            print(
                "    Ensure 'graphviz' is installed on your system (e.g., 'sudo apt install graphviz')"
            )


if __name__ == "__main__":
    main()
