#!/usr/bin/env -S uv run --script
# /// script
# requires-python = ">=3.8"
# dependencies = [
#     "requests",
#     "graphviz",
#     "python-debian",
# ]
# ///
"""Big thanks to https://github.com/hkhonming for sharing this tool with me.

This script can/may be changed to fit my needs. Please use with caution.
"""
import argparse
import requests
import gzip
import lzma
import sys
from graphviz import Digraph
from debian.deb822 import Sources, Packages, PkgRelation


def fetch_repo_file(base_url, dist, path):
    """Fetches and decompresses a repository file (Packages or Sources)."""
    extensions = ["xz", "gz"]
    # Ensure URL ends with /
    if not base_url.endswith("/"):
        base_url += "/"

    for ext in extensions:
        url = f"{base_url}{path}.{ext}"
        try:
            print(f"[-] Attempting to fetch: {url}")
            response = requests.get(url, timeout=10)
            if response.status_code == 200:
                print(f"[+] Successfully fetched {url}")
                if ext == "xz":
                    return lzma.decompress(response.content).decode("utf-8")
                else:
                    return gzip.decompress(response.content).decode("utf-8")
        except Exception as e:
            print(f"[!] Connection error: {e}")
            continue

    print(f"[!] Error: Could not find or download file at {base_url}{path}")
    sys.exit(1)


def fetch_packages_file(base_url, dist, arch):
    """Fetches and decompresses the Packages file from the PPA."""
    base_path = f"dists/{dist}/main/binary-{arch}/Packages"
    return fetch_repo_file(base_url, dist, base_path)


def fetch_sources_file(base_url, dist):
    """Fetches and decompresses the Sources file from the PPA."""
    base_path = f"dists/{dist}/main/source/Sources"
    return fetch_repo_file(base_url, dist, base_path)


def parse_packages(content):
    """Parses the Packages file content using python-debian."""
    return list(Packages.iter_paragraphs(content))


def parse_sources(content):
    """Parses the Sources file content using python-debian."""
    return list(Sources.iter_paragraphs(content))


def get_source_name(pkg_info):
    """Extracts the Source package name."""
    if "Source" in pkg_info:
        return pkg_info["Source"].split(" ")[0].strip()
    return pkg_info["Package"]


def parse_dependency_names(dep_field):
    """Parses a dependency field and returns a list of package names.

    Uses python-debian's PkgRelation to properly handle:
    - Version constraints: (>= 1.0)
    - Architecture qualifiers: [amd64 arm64]
    - Build profiles: <!nocheck>, <!pkg.foo.bar>
    - Alternatives: pkg1 | pkg2 (returns first alternative)
    - Architecture qualifiers on package: pkg:any, pkg:native

    Args:
        dep_field: Raw dependency string from Depends/Build-Depends field

    Returns:
        List of package names (strings)
    """
    if not dep_field:
        return []

    try:
        relations = PkgRelation.parse_relations(dep_field)
    except Exception:
        # Fallback to empty if parsing fails
        return []

    pkg_names = []
    for relation in relations:
        # Each relation is a list of alternatives, pick the first one
        if relation:
            first_alt = relation[0]
            pkg_name = first_alt.get("name", "")
            if pkg_name:
                # Remove architecture qualifier suffix (:any, :native, etc.)
                if ":" in pkg_name:
                    pkg_name = pkg_name.split(":")[0]
                pkg_names.append(pkg_name)

    return pkg_names


def build_binary_graph(packages):
    """Generates a graph based on Binary Package dependencies."""
    dot = Digraph(comment="PPA Binary Dependency Chart")
    dot.attr(rankdir="LR")
    dot.attr("node", shape="box", style="filled", fillcolor="lightblue")

    # Map of all binaries available in this PPA
    ppa_binaries = {p["Package"] for p in packages}

    # Track added nodes to avoid duplicates
    added_nodes = set()

    for pkg in packages:
        pkg_name = pkg["Package"]

        if pkg_name not in added_nodes:
            dot.node(pkg_name, pkg_name)
            added_nodes.add(pkg_name)

        depends_raw = pkg.get("Depends", "")
        dep_names = parse_dependency_names(depends_raw)

        for target_bin in dep_names:
            # ONLY draw if target is also in the PPA
            if target_bin in ppa_binaries:
                dot.edge(pkg_name, target_bin)

    return dot


def build_source_graph(sources):
    """Generates a graph based on Source Package Build-Depends.

    Returns:
        tuple: (Digraph, set of edges, set of source names)
    """
    dot = Digraph(comment="PPA Source Dependency Chart")
    dot.attr(rankdir="LR")
    dot.attr("node", shape="component", style="filled", fillcolor="#E0E0E0")

    # Map Binary -> Source (from the Binary field in Sources)
    bin_to_source_map = {}
    ppa_sources = set()

    for src in sources:
        src_name = src["Package"]
        ppa_sources.add(src_name)

        # The Binary field lists all binary packages built from this source
        binaries = src.get("Binary", "")
        for bin_name in binaries.split(","):
            bin_name = bin_name.strip()
            if bin_name:
                bin_to_source_map[bin_name] = src_name

    edges = set()

    for src in sources:
        src_from = src["Package"]
        build_depends_raw = src.get("Build-Depends", "")
        dep_names = parse_dependency_names(build_depends_raw)

        for bin_target in dep_names:
            # Resolve target binary to target source
            # If bin_target is not in map, it's external (system) -> Skip
            if bin_target in bin_to_source_map:
                src_to = bin_to_source_map[bin_target]

                if src_from != src_to:
                    edges.add((src_from, src_to))

    for src in ppa_sources:
        dot.node(src, src)

    for src_from, src_to in edges:
        dot.edge(src_from, src_to)

    return dot, edges, ppa_sources


def find_strongly_connected_components(sources, edges):
    """Finds strongly connected components using Tarjan's algorithm.

    Returns:
        list of sets: Each set contains package names in one SCC
    """
    # Build adjacency list
    graph = {src: set() for src in sources}
    for src_from, src_to in edges:
        graph[src_from].add(src_to)

    index_counter = [0]
    stack = []
    lowlinks = {}
    index = {}
    on_stack = {}
    sccs = []

    def strongconnect(node):
        index[node] = index_counter[0]
        lowlinks[node] = index_counter[0]
        index_counter[0] += 1
        stack.append(node)
        on_stack[node] = True

        for successor in graph[node]:
            if successor not in index:
                strongconnect(successor)
                lowlinks[node] = min(lowlinks[node], lowlinks[successor])
            elif on_stack.get(successor, False):
                lowlinks[node] = min(lowlinks[node], index[successor])

        if lowlinks[node] == index[node]:
            scc = set()
            while True:
                successor = stack.pop()
                on_stack[successor] = False
                scc.add(successor)
                if successor == node:
                    break
            sccs.append(scc)

    for node in sources:
        if node not in index:
            strongconnect(node)

    return sccs


def compute_dependency_groups(sources, edges):
    """Computes dependency groups (topological levels) for source packages.

    Group 1: Packages with no dependencies within the PPA
    Group 2: Packages that only depend on Group 1 packages
    Group N: Packages that only depend on packages in groups < N

    Handles cyclic dependencies by detecting SCCs and marking them appropriately.

    Returns:
        tuple: (groups, cycles_info)
            - groups: list of dicts with 'packages' and 'is_cycle' keys
            - cycles_info: dict mapping cycle packages to their cycle members
    """
    # Find strongly connected components
    sccs = find_strongly_connected_components(sources, edges)

    # Identify cycles (SCCs with more than one node)
    cycles = [scc for scc in sccs if len(scc) > 1]
    cycle_packages = set()
    cycles_info = {}
    for cycle in cycles:
        for pkg in cycle:
            cycle_packages.add(pkg)
            cycles_info[pkg] = cycle

    if cycles:
        cycle_names = [', '.join(sorted(c)) for c in cycles]
        print(f"[!] Warning: Circular dependencies detected:")
        for i, cycle in enumerate(cycles, 1):
            print(f"    Cycle {i}: {', '.join(sorted(cycle))}")

    # Build adjacency list: src -> set of dependencies
    dependencies = {src: set() for src in sources}
    for src_from, src_to in edges:
        dependencies[src_from].add(src_to)

    # Create a mapping from package to its SCC representative
    pkg_to_scc = {}
    scc_to_pkgs = {}
    for i, scc in enumerate(sccs):
        rep = f"__scc_{i}__"
        scc_to_pkgs[rep] = scc
        for pkg in scc:
            pkg_to_scc[pkg] = rep

    # Build contracted graph (SCCs as nodes)
    contracted_deps = {f"__scc_{i}__": set() for i in range(len(sccs))}
    for src_from, src_to in edges:
        rep_from = pkg_to_scc[src_from]
        rep_to = pkg_to_scc[src_to]
        if rep_from != rep_to:
            contracted_deps[rep_from].add(rep_to)

    # Topological sort on contracted graph
    groups = []
    assigned = set()
    scc_reps = set(contracted_deps.keys())

    while len(assigned) < len(scc_reps):
        current_group_reps = []
        for rep in scc_reps:
            if rep in assigned:
                continue
            if contracted_deps[rep].issubset(assigned):
                current_group_reps.append(rep)

        if not current_group_reps:
            # This shouldn't happen after SCC contraction, but handle it
            remaining = [rep for rep in scc_reps if rep not in assigned]
            for rep in remaining:
                pkgs = scc_to_pkgs[rep]
                is_cycle = len(pkgs) > 1
                groups.append({'packages': sorted(pkgs), 'is_cycle': is_cycle, 'cycles': []})
            break

        # Collect all packages at this level, tracking which are cyclic
        level_packages = []
        level_cycles = []  # List of cycle sets at this level

        for rep in current_group_reps:
            pkgs = scc_to_pkgs[rep]
            if len(pkgs) > 1:
                # Cyclic SCC - sort by internal dependency count
                pkg_dep_count = {}
                for pkg in pkgs:
                    internal_deps = dependencies[pkg] & pkgs
                    pkg_dep_count[pkg] = len(internal_deps)
                sorted_pkgs = sorted(pkgs, key=lambda p: (pkg_dep_count[p], p))
                level_packages.extend(sorted_pkgs)
                level_cycles.append(pkgs)
            else:
                level_packages.extend(pkgs)

        # Sort non-cyclic packages alphabetically, keep cyclic packages in their order
        cyclic_pkg_set = set()
        for cycle in level_cycles:
            cyclic_pkg_set.update(cycle)

        non_cyclic = sorted([p for p in level_packages if p not in cyclic_pkg_set])
        cyclic_ordered = [p for p in level_packages if p in cyclic_pkg_set]

        # Combine: non-cyclic first, then cyclic
        final_packages = non_cyclic + cyclic_ordered

        groups.append({
            'packages': final_packages,
            'is_cycle': bool(level_cycles),
            'cycles': level_cycles
        })

        assigned.update(current_group_reps)

    return groups, cycles_info


def print_dependency_groups(groups, cycles_info, edges):
    """Prints dependency groups in a formatted way.

    Args:
        groups: list of dicts with 'packages', 'is_cycle', and 'cycles' keys
        cycles_info: dict mapping cycle packages to their cycle members
        edges: set of (from, to) tuples representing dependencies
    """
    # Build dependency lookup
    deps_map = {}
    for src_from, src_to in edges:
        if src_from not in deps_map:
            deps_map[src_from] = set()
        deps_map[src_from].add(src_to)

    print("\n" + "=" * 60)
    print("BUILD ORDER (Dependency Groups)")
    print("=" * 60)
    print("Packages in the same group can be built in parallel.")
    print("Groups must be built in order (Group 1 first, then Group 2, etc.)")
    print("-" * 60)

    group_num = 1
    for group_info in groups:
        packages = group_info['packages']
        cycles = group_info.get('cycles', [])

        # Build set of all cyclic packages in this group
        cyclic_pkgs = set()
        for cycle in cycles:
            cyclic_pkgs.update(cycle)

        has_cycles = bool(cyclic_pkgs)
        non_cyclic_pkgs = [p for p in packages if p not in cyclic_pkgs]

        if has_cycles:
            print(f"\nGroup {group_num} ({len(packages)} packages) [contains CYCLIC dependencies]:")

            # Show non-cyclic packages first
            if non_cyclic_pkgs:
                print(f"  Regular packages:")
                print(f"    {', '.join(non_cyclic_pkgs)}")

            # Show cyclic packages with their dependencies
            print(f"  Cyclic packages (require bootstrapping):")
            for pkg in packages:
                if pkg in cyclic_pkgs:
                    cycle_deps = deps_map.get(pkg, set()) & cyclic_pkgs
                    if cycle_deps:
                        print(f"    {pkg} -> depends on: {', '.join(sorted(cycle_deps))}")
                    else:
                        print(f"    {pkg}")
        else:
            print(f"\nGroup {group_num} ({len(packages)} package{'s' if len(packages) > 1 else ''}):")
            print(f"  {', '.join(packages)}")

        group_num += 1

    # Print summary if there were cycles
    if cycles_info:
        print("\n" + "-" * 60)
        print("CYCLE RESOLUTION NOTES:")
        print("  Packages marked as cyclic require bootstrapping:")
        print("  1. Build with reduced features or stub dependencies")
        print("  2. Rebuild with full dependencies after initial pass")

    print("\n" + "=" * 60)


def main():
    parser = argparse.ArgumentParser(description="Generate PPA Dependency Charts")

    # Required Args
    parser.add_argument(
        "--ppa",
        required=True,
        help="The base URL of the PPA (e.g., https://ppa.../ubuntu/)",
    )

    # Optional Args with Defaults
    parser.add_argument(
        "--dist", default="noble", help="Distribution codename (default: noble)"
    )
    parser.add_argument("--arch", default="arm64", help="Architecture (default: arm64)")
    parser.add_argument(
        "--output",
        default="dependency_graph",
        help="Output filename (without extension)",
    )
    parser.add_argument(
        "--mode",
        choices=["binary", "source"],
        default="binary",
        help="Graph mode: 'binary' (package-to-package) or 'source' (aggregated by source)",
    )

    args = parser.parse_args()

    # 1. Fetch and Parse
    if args.mode == "binary":
        print(f"[*] Fetching Packages metadata for {args.dist}/{args.arch}...")
        content = fetch_packages_file(args.ppa, args.dist, args.arch)
        packages = parse_packages(content)
        print(f"[*] Found {len(packages)} binary packages.")

        # 2. Build Graph
        print("[*] Generating BINARY level dependency graph...")
        dot = build_binary_graph(packages)
    else:
        print(f"[*] Fetching Sources metadata for {args.dist}...")
        content = fetch_sources_file(args.ppa, args.dist)
        sources = parse_sources(content)
        print(f"[*] Found {len(sources)} source packages.")

        # 2. Build Graph
        print("[*] Generating SOURCE level dependency graph (using Build-Depends)...")
        dot, edges, ppa_sources = build_source_graph(sources)

        # 3. Compute and print dependency groups
        groups, cycles_info = compute_dependency_groups(ppa_sources, edges)
        print_dependency_groups(groups, cycles_info, edges)

    # 4. Render
    try:
        output_path = dot.render(args.output, format="png", cleanup=True)
        print(f"[SUCCESS] Chart saved to: {output_path}")
    except Exception as e:
        print(f"[!] Error rendering graph: {e}")
        print(
            "    Ensure 'graphviz' is installed on your system (e.g., 'sudo apt install graphviz')"
        )


if __name__ == "__main__":
    main()
